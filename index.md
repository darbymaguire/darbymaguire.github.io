![image](https://user-images.githubusercontent.com/77426275/104655606-eeb1ba80-568b-11eb-9d37-7a1a2e2163c9.png)

## Who am I?

I ask myself the same question all too often. Currently, I am in my final year of studying Computer Science at the United States Naval Academy. I'll graduate in May 2021 and am looking to continue developing software that makes a difference in the world. I specialize in Machine Learning and Data Science, having taken many classes and done multiple projects using Artifical Intelligence, Natural Language Processing, and more. 

Keep scrolling to take an inside look at my recent projects!

||     ||     ||
\/     \/     \/

### New project! Detection of Sharks in Coastal Waters via Aerial Footage

Thanks to the kind folks over at the Benioff Ocean Initiative, I've been able to use my free time to combine my love of sharks with my love of programming. They provided me with over 5.5 hours of drone footage of the Southern California coast, and I'm in the process of creating an AI that will be able to detect and approximate the size of sharks. 

### Sentiment Analysis of Twitter Posts

Armed with 790 MB of old tweets, I built two types of classifiers for positive, negative, and objective sentiment. Using millions of tweets amassed from users all over the world produced the unexpected challenge of cleaning the data of slang, poor grammar, non-ascii characters, and sarcasm before being able to produce an accurate classification. The first classifier used a sentiment lexicon, and the second used a logistic regression classifier. In the end, both classifiers approached an astonishing 60% accuracy, which leaves much room for improvement (but overall, not terrible for a basic language model!). 

### Predicted Success of Reddit Posts

After experimenting with Reddit's PRAW API, myself and two other teammates created a language model to determine how successful a Reddit post might become. PRAW became a jumping-off point for us, and we ended up accumulating over 1.65 billion comments in JSON format using pushshift.io that we would use to train and test our language model. We created a lightweight Recurrent Neural Network (RNN) using Long Short-Term Memory (LSTM) to predict various classifications of success levels. Using an 80/20 train/test split, our AI achieved an impressive 87% accuracy. 

### Word Arthmetic, Twitter "Search Engine"

What do you think "cat - mean + nice" equals? While a cat person might disagree, my Word2Vec program calculated it to equal "dog"! I transformed a simple numerical calulator into a more complex word calculator using 66MB of pre-trained embeddings and creating word vectors. My calculator really got down to the true meaning of certain words, as seen in the procuded equation "job - fun + office = federal".

Also using a Word2Vec model, I brought back my massive Twitter dataset to create a sort of "search engine" that would take a sentence or phrase as input and return tweets most similar to it using word embeddings and a cosine comparison function.

### CKY Parser

In an effort to master sentence parsing to create maximum accuracy in NLP, I implemented a CKY algorithm that was able to parse sentences better than a novice linguist like myself could. I tested my algorithm on millions of parse trees created by scanning complex sentences pulled from the Wall Street Journal.

## Enough with the technicalities, who am I away from the screen?

Netflix might call me Halt and Catch Fire's biggest fan, but when I'm not working on my latest garage project or learning a new programming language, I'm usually outdoors doing something on the border between epic and idiotic. My risk-taking and daring personality traits are not exclusive to my programming life, after all. 

I love running, and by far my best experiences have been doing a 40-mile ultramarathon with zero training whatsoever, along with running the Marine Corps Marathon in 2019 for a non-profit called Back on My Feet that combats homelessness throughout the United States.

When I'm not running, you can also find me on the slopes or in the surf, living in sunny California gives me the incredible opportunity to even do both in one day. I'm also a big reader (thanks to my kindle!) and love any and all Margaret Atwood.
